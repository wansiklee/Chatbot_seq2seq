{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chatbot_seq2seq_keras",
      "version": "0.3.2",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuVqmflE8lbG",
        "colab_type": "code",
        "outputId": "fc0d350f-9331-4b98-b2fe-5ebd04fc2629",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers, losses, metrics\n",
        "from keras import preprocessing\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re\n",
        "\n",
        "from konlpy.tag import Okt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsbwyYApQ62y",
        "colab_type": "text"
      },
      "source": [
        "## 데이터 로드 및 파라미터 지정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5D3kxq498_Wy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 태그 단어\n",
        "PAD = \"<PADDING>\"\n",
        "STA = \"<START>\"\n",
        "END = \"<END>\"\n",
        "OOV = \"<OOV>\"\n",
        "\n",
        "# 태그 인덱스\n",
        "PAD_INDEX = 0\n",
        "STA_INDEX = 1\n",
        "END_INDEX = 2\n",
        "OOV_INDEX = 3\n",
        "\n",
        "# 데이터 타입\n",
        "ENCODER_INPUT = 0\n",
        "DECODER_INPUT = 1\n",
        "DECODER_TARGET = 2\n",
        "\n",
        "# 한 문장에서 단어 시퀀스의 최대 개수\n",
        "max_sequences = 30\n",
        "\n",
        "# 임베딩 벡터 차원\n",
        "embedding_dim = 100\n",
        "\n",
        "# LSTM 히든레이어 차원\n",
        "lstm_hidden_layer = 128\n",
        "\n",
        "# 정규표현식 필터\n",
        "RE_FILTER = re.compile(\"[.,!?\\\"':;~()]\")\n",
        "\n",
        "# 챗봇 데이터 로드\n",
        "chatbot_data = pd.read_csv('./data_in/ChatbotData .csv', encoding='utf-8')\n",
        "question, answer = list(chatbot_data['Q']), list(chatbot_data['A'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wuhllnl4Q_sL",
        "colab_type": "text"
      },
      "source": [
        "코랩 RAM 제한으로 데이터 개수 제한"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cUj4NLPoffY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "question = question[:100]\n",
        "answer = answer[:100]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZHBjRuKNsYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 형태소 분석 함수\n",
        "def pos_tag(sentences):\n",
        "  \n",
        "  okt = Okt()\n",
        "  sentences_pos = []\n",
        "  \n",
        "  for sentence in sentences:\n",
        "    # 특수기호 제거\n",
        "    sentence = re.sub(RE_FILTER, \"\", sentence)\n",
        "    \n",
        "    # 배열인 형태소분석의 출력을 띄어쓰기로 구분하여 붙임\n",
        "    sentence = \" \".join(okt.morphs(sentence))\n",
        "    sentences_pos.append(sentence)\n",
        "    \n",
        "  return sentences_pos"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpd0XZhcOSxe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "question = pos_tag(question)\n",
        "answer = pos_tag(answer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6sxKlA1Olgt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 질문과 대답 문장들을 하나로 합침\n",
        "sentences = []\n",
        "sentences.extend(question)\n",
        "sentences.extend(answer)\n",
        "\n",
        "words = []\n",
        "\n",
        "# 단어들의 배열 생성\n",
        "for sentence in sentences:\n",
        "  for word in sentence.split():\n",
        "    words.append(word)\n",
        "    \n",
        "# 길이가 0인 단어는 삭제\n",
        "words = [word for word in words if len(word) > 0]\n",
        "\n",
        "# 중복된 단어 삭제\n",
        "words = list(set(words))\n",
        "\n",
        "# 제일 앞에 태그 단어 삽입\n",
        "words[:0] = [PAD, STA, END, OOV]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TZBxLgSP5Up",
        "colab_type": "code",
        "outputId": "c4ffa895-bab5-4712-832a-6418db4f948d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# 단어 개수\n",
        "len(words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "454"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9QieOo7P84E",
        "colab_type": "code",
        "outputId": "6e6e6c74-f0e9-4c6f-f3aa-34b5dfc3dd4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# 단어 출력\n",
        "words[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<PADDING>', '<START>', '<END>', '<OOV>', '하겠어', '참', '가고', '졸려', '친구', '나갔어']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Krc2FW2SQAY8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 단어와 인덱스의 딕셔너리 생성\n",
        "word_to_index = {word: index for index, word in enumerate(words)}\n",
        "index_to_word = {index: word for index, word in enumerate(words)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5aYQEbBQb6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 문장을 인덱스로 변환\n",
        "def convert_text_to_index(sentences, vocabulary, type):\n",
        "  \n",
        "  sentences_index = []\n",
        "  \n",
        "  # 모든 문장에 대해 반복\n",
        "  for sentence in sentences:\n",
        "    sentence_index = []\n",
        "    \n",
        "    # 디코더 입력일 경우 맨 앞에 START 태그 추가\n",
        "    if type == DECODER_INPUT:\n",
        "      sentence_index.extend([vocabulary[STA]])\n",
        "      \n",
        "    # 문장의 단어들을 띄어쓰기로 분리\n",
        "    for word in sentence.split():\n",
        "      if vocabulary.get(word) is not None:\n",
        "        sentence_index.extend([vocabulary[word]])\n",
        "      else:\n",
        "        sentence_index.extend([vocabulary[OOV]])\n",
        "        \n",
        "    # 최대 길이 검사\n",
        "    if type == DECODER_TARGET:\n",
        "      # 디코더 타겟값일 경우 맨 뒤에 END 태그 추가\n",
        "      if len(sentence_index) >= max_sequences:\n",
        "        sentence_index = sentence_index[:max_sequences - 1] + [vocabulary[END]]\n",
        "      else:\n",
        "        sentence_index += [vocabulary[END]]\n",
        "    else:\n",
        "      if len(sentence_index) > max_sequences:\n",
        "        sentence_index = sentence_index[:max_sequences]\n",
        "        \n",
        "    # 최대 길이에 없는 공간은 패딩 인덱스로 채움\n",
        "    sentence_index += (max_sequences - len(sentence_index)) * [vocabulary[PAD]]\n",
        "    \n",
        "    # 문장의 인덱스 배열을 추가\n",
        "    sentences_index.append(sentence_index)\n",
        "  \n",
        "  return np.asarray(sentences_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciq_bBLZUO0S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 인코더 입력 인덱스 반환\n",
        "x_encoder = convert_text_to_index(question, word_to_index, ENCODER_INPUT)\n",
        "\n",
        "# 디코더 입력 인덱스 반환\n",
        "x_decoder = convert_text_to_index(answer, word_to_index, DECODER_INPUT)\n",
        "\n",
        "# 디코더 타겟 인덱스 반환\n",
        "y_decoder = convert_text_to_index(answer, word_to_index, DECODER_TARGET)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqiHw7GRYt15",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_decoder = tf.one_hot(y_decoder, len(word_to_index))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiFKEwQ0ftst",
        "colab_type": "code",
        "outputId": "b8fef599-08f0-4c76-e467-a9a7aa48995e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_decoder.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([Dimension(100), Dimension(30), Dimension(454)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hD5qhuVWSCVr",
        "colab_type": "text"
      },
      "source": [
        "## 모델 정의 및 학습하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF7kOMHAV9Xt",
        "colab_type": "code",
        "outputId": "33a9af3e-c603-4e42-d650-a537e71dd780",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "source": [
        "# ---------------------------------\n",
        "# 훈련모델 인코더 정의\n",
        "# ---------------------------------\n",
        "\n",
        "# 입력 문장의 인덱스 시퀀스를 입력으로 받음\n",
        "encoder_inputs = layers.Input(shape=(None,))\n",
        "\n",
        "# 임베딩 레이어\n",
        "encoder_outputs = layers.Embedding(len(words), embedding_dim)(encoder_inputs)\n",
        "\n",
        "# return_state가 True면 상태값 리턴\n",
        "# LSTM은 state_h(hidden state)와 state_c(cell state) 2개의 상태 존재\n",
        "encoder_outputs, state_h, state_c = layers.LSTM(lstm_hidden_layer,\n",
        "                                                dropout=0.1,\n",
        "                                                recurrent_dropout=0.5,\n",
        "                                                return_state=True)(encoder_outputs)\n",
        "\n",
        "# 히든 상태와 셀 상태를 하나로 묶음\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "\n",
        "# ---------------------------------\n",
        "# 훈련모델 디코더 정의\n",
        "# ---------------------------------\n",
        "\n",
        "decoder_inputs = layers.Input(shape=(None,))\n",
        "\n",
        "# 임베딩 레이어\n",
        "decoder_embedding = layers.Embedding(len(words), embedding_dim)\n",
        "decoder_outputs = decoder_embedding(decoder_inputs)\n",
        "\n",
        "# 인코더와 달리 return_sequences를 True로 설정하여 모든 타임 스텝 출력값 리턴\n",
        "# 모든 타임 스텝의 출력값들을 다음 레이어의 Dense()로 처리하기 위함\n",
        "decoder_lstm = layers.LSTM(lstm_hidden_layer,\n",
        "                           dropout=0.1,\n",
        "                           recurrent_dropout=0.5,\n",
        "                           return_state=True,\n",
        "                           return_sequences=True)\n",
        "\n",
        "# initial_state를 인코더의 상태로 초기화\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_outputs,\n",
        "                                     initial_state=encoder_states)\n",
        "\n",
        "# 단어의 개수만큼 노드의 개수를 설정하여 원-핫 형식으로 각 단어 인덱스를 출력\n",
        "decoder_dense = layers.Dense(len(words), activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "\n",
        "# ---------------------------------\n",
        "# 훈련모델 정의\n",
        "# ---------------------------------\n",
        "\n",
        "# 입력과 출력으로 함수형 API 모델 생성\n",
        "model = models.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# 학습 방법 설정\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0820 06:07:24.388791 139659571902336 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0820 06:07:24.391278 139659571902336 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0820 06:07:24.395896 139659571902336 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0820 06:07:24.550677 139659571902336 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0820 06:07:24.562307 139659571902336 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0820 06:07:25.422957 139659571902336 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0820 06:07:25.447458 139659571902336 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mlv4DjV6ixcb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ---------------------------------\n",
        "# 예측모델 인코더 정의\n",
        "# ---------------------------------\n",
        "\n",
        "# 훈련모델의 인코더 상태를 사용하여 예측 모델 인코더 설정\n",
        "encoder_model = models.Model(encoder_inputs, encoder_states)\n",
        "\n",
        "\n",
        "# ---------------------------------\n",
        "# 예측모델 디코더 정의\n",
        "# ---------------------------------\n",
        "\n",
        "# 예측시에는 훈련시와 달리 타임 스텝을 한 단계씩 수행\n",
        "# 매번 이전 디코더 상태를 입력으로 받아서 새로 설정\n",
        "decoder_state_input_h = layers.Input(shape=(lstm_hidden_layer,))\n",
        "decoder_state_input_c = layers.Input(shape=(lstm_hidden_layer,))\n",
        "decoder_state_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# 임베딩 레이어\n",
        "decoder_outputs = decoder_embedding(decoder_inputs)\n",
        "\n",
        "# LSTM 레이어\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_outputs, initial_state=decoder_state_inputs)\n",
        "\n",
        "# 히든 상태와 셀 상태를 하나로 묶음\n",
        "decoder_states = [state_h, state_c]\n",
        "\n",
        "# Dense 레이어를 통해 원-핫 형식으로 각 단어 인덱스를 출력\n",
        "decoder_outputs  = decoder_dense(decoder_outputs)\n",
        "\n",
        "# 예측 모델 디코더 설정\n",
        "decoder_model = models.Model([decoder_inputs] + decoder_state_inputs,\n",
        "                      [decoder_outputs] + decoder_states)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqyKEEkrk2QC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 인덱스를 문장으로 변환\n",
        "def convert_index_to_text(indexs, vocabulary): \n",
        "    \n",
        "    sentence = ''\n",
        "    \n",
        "    # 모든 문장에 대해서 반복\n",
        "    for index in indexs:\n",
        "        if index == END_INDEX:\n",
        "            # 종료 인덱스면 중지\n",
        "            break;\n",
        "        if vocabulary.get(index) is not None:\n",
        "            # 사전에 있는 인덱스면 해당 단어를 추가\n",
        "            sentence += vocabulary[index]\n",
        "        else:\n",
        "            # 사전에 없는 인덱스면 OOV 단어를 추가\n",
        "            sentence.extend([vocabulary[OOV_INDEX]])\n",
        "            \n",
        "        # 빈칸 추가\n",
        "        sentence += ' '\n",
        "\n",
        "    return sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suM_hZW5lY6N",
        "colab_type": "code",
        "outputId": "d34918f1-5ae9-48e1-f124-00783e70b101",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# 에폭 반복\n",
        "# 훈련 시작\n",
        "history = model.fit([x_encoder, x_decoder],\n",
        "                    y_decoder,\n",
        "                    epochs=100,\n",
        "                    steps_per_epoch=64,\n",
        "                    verbose=0)\n",
        "    \n",
        "# 정확도와 손실 출력\n",
        "print('accuracy :', history.history['acc'][-1])\n",
        "print('loss :', history.history['loss'][-1])\n",
        "    \n",
        "# 문장 예측 테스트\n",
        "# (3 박 4일 놀러 가고 싶다) -> (여행 은 언제나 좋죠)\n",
        "input_encoder = x_encoder[2].reshape(1, x_encoder[2].shape[0])\n",
        "input_decoder = x_decoder[2].reshape(1, x_decoder[2].shape[0])\n",
        "results = model.predict([input_encoder, input_decoder])\n",
        "    \n",
        "# 결과의 원핫인코딩 형식을 인덱스로 변환\n",
        "# 1축을 기준으로 가장 높은 값의 위치를 구함\n",
        "indexs = np.argmax(results[0], 1) \n",
        "    \n",
        "# 인덱스를 문장으로 변환\n",
        "sentence = convert_index_to_text(indexs, index_to_word)\n",
        "print(sentence)\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy : 1.0\n",
            "loss : 3.7689041907373877e-06\n",
            "여행 은 언제나 좋죠 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl4_EqA1ms4J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 예측을 위한 입력 생성\n",
        "def make_predict_input(sentence):\n",
        "\n",
        "    sentences = []\n",
        "    sentences.append(sentence)\n",
        "    sentences = pos_tag(sentences)\n",
        "    input_seq = convert_text_to_index(sentences, word_to_index, ENCODER_INPUT)\n",
        "    \n",
        "    return input_seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmGSr7e8x3Xy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 텍스트 생성\n",
        "def generate_text(input_seq):\n",
        "    \n",
        "    # 입력을 인코더에 넣어 마지막 상태 구함\n",
        "    states = encoder_model.predict(input_seq)\n",
        "\n",
        "    # 목표 시퀀스 초기화\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    \n",
        "    # 목표 시퀀스의 첫 번째에 <START> 태그 추가\n",
        "    target_seq[0, 0] = STA_INDEX\n",
        "    \n",
        "    # 인덱스 초기화\n",
        "    indexs = []\n",
        "    \n",
        "    # 디코더 타임 스텝 반복\n",
        "    while 1:\n",
        "        # 디코더로 현재 타임 스텝 출력 구함\n",
        "        # 처음에는 인코더 상태를, 다음부터 이전 디코더 상태로 초기화\n",
        "        decoder_outputs, state_h, state_c = decoder_model.predict(\n",
        "                                                [target_seq] + states)\n",
        "\n",
        "        # 결과의 원핫인코딩 형식을 인덱스로 변환\n",
        "        index = np.argmax(decoder_outputs[0, 0, :])\n",
        "        indexs.append(index)\n",
        "        \n",
        "        # 종료 검사\n",
        "        if index == END_INDEX or len(indexs) >= max_sequences:\n",
        "            break\n",
        "\n",
        "        # 목표 시퀀스를 바로 이전의 출력으로 설정\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = index\n",
        "        \n",
        "        # 디코더의 이전 상태를 다음 디코더 예측에 사용\n",
        "        states = [state_h, state_c]\n",
        "\n",
        "    # 인덱스를 문장으로 변환\n",
        "    sentence = convert_index_to_text(indexs, index_to_word)\n",
        "        \n",
        "    return sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RN6fMuEPRN3I",
        "colab_type": "text"
      },
      "source": [
        "## 예측하기\n",
        "\n",
        "* 데이터셋에 있는 '3박4일 놀러가고 싶다'는 예측을 잘 하였다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gtOSTpay0Do",
        "colab_type": "code",
        "outputId": "90585c2d-44b9-4971-b5d0-a17172c9688b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "input_seq = make_predict_input('3박4일 놀러가고 싶다')\n",
        "input_seq"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[440, 438, 429, 161,   6,  86,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaOmCnbhy7XF",
        "colab_type": "code",
        "outputId": "33020630-edb7-42d1-e416-24d815d051f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sentence = generate_text(input_seq)\n",
        "sentence"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'여행 은 언제나 좋죠 '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLaireUhRWcT",
        "colab_type": "text"
      },
      "source": [
        "* '아무것도 하기싫다'도 잘 예측하는 모습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLb5rvUTzApU",
        "colab_type": "code",
        "outputId": "78bafdfc-3840-4700-c506-8896cdcc74e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "input_seq = make_predict_input('아무것도 하기싫다')\n",
        "sentence = generate_text(input_seq)\n",
        "sentence"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'이럴 때 잘 쉬는 게 중요해요 '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGzmpZL8RbDd",
        "colab_type": "text"
      },
      "source": [
        "* 하지만 다른 문장들은 쉽게 예측하지 못하였다. 이런 이유는 데이터셋을 100개 정도밖에 사용하지 않았기 때문이고 \n",
        "데이터셋을 모두 학습시키면 성능이 올라갈 것이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WvKh1cIzGqN",
        "colab_type": "code",
        "outputId": "c70f3044-6ca5-424b-f1cb-478faef583f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "input_seq = make_predict_input('집에 불 키고 나왔다')\n",
        "sentence = generate_text(input_seq)\n",
        "sentence"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'무모한 결정 을 내 리지 마세요 '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4DjHqMARvGC",
        "colab_type": "text"
      },
      "source": [
        "데이터셋을 모두 돌리고 싶었지만 코랩 RAM이 자꾸 나가서 세션이 종료되는 바람에 모두 돌리지는 못한게 아쉬움이 크다. 하지만 tensorflow estimator로 구현된 것을 케라스로 이해하면서 바꾸니 쉽게 바꿀 수 있었다."
      ]
    }
  ]
}